# Movies_ETL

## Overview

A small work was carried out at a fictitious company where what was worked on were the bases of the ETL process (extract, transform, load), where they learned about how to extract information from different sources and how to unite these same databases in one alone .

We also worked on cleaning the data in different ways, starting with an exploratory analysis to get a general image of how the information was constituted, and we got to see how regular expressions were used.

Finally, the information loading part was carried out, where we exported our work to databases within another system such as Postgress SQL

## Resources

Sofware : Sql, PostgreSQL , PgAdmin4, Jupyter, Python

## Results

The work was divided into 4 parts:
- Write an ETL Function to Read Three Data Files:
  Write a function that reads in the three data files and creates three separate DataFrames


- Extract and Transform the Wikipedia Data:
  Extract and transform the Wikipedia data so that I can merge it with the Kaggle metadata
  
- Extract and Transform the Kaggle data:
  Extract and transform the Kaggle metadata and MovieLens rating data, then convert the transformed data into separate DataFrames. After  all of this was completed I had to merge   the different databases into one alone
  
- Create the Movie Database:
  Add the movies_df DataFrame and MovieLens rating CSV data to a SQL database
  
  ![image](https://user-images.githubusercontent.com/66183125/141742374-e8c2ca6c-d582-49c4-821e-696806e8dfed.png)
